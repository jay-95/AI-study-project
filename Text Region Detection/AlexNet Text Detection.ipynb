{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"AlexNet Text Detection.ipynb","provenance":[],"authorship_tag":"ABX9TyMf2r2rEFgjIFGrfoM8xNlh"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"8u8dRIdn1QwE","colab_type":"code","colab":{}},"source":["import os\n","import zipfile\n","\n","local_zip = '/tmp/text region detectoin data set.zip'\n","zip_ref = zipfile.ZipFile(local_zip, 'r')\n","zip_ref.extractall('/tmp/text region detectoin data set')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"dhxCLteYfWf_","colab_type":"code","colab":{}},"source":["# Directory with our text region pictures\n","train_text_dir = os.path.join('/tmp/text region detectoin data set/text region')\n","\n","# Directory with our non text region pictures\n","train_non_text_dir = os.path.join('/tmp/text region detectoin data set/non text region')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"4GAM76k9gRcJ","colab_type":"code","outputId":"6080883b-fbf3-4c86-87f4-a478e5045b3c","executionInfo":{"status":"ok","timestamp":1587710669961,"user_tz":-540,"elapsed":819,"user":{"displayName":"Wonjai Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJUXJXii0iTXALRF0ZIAgTENwYzLvrIrce_oU8Uw=s64","userId":"05081401112829537892"}},"colab":{"base_uri":"https://localhost:8080/","height":109}},"source":["train_text_names = os.listdir(train_text_dir)\n","print(train_text_names[:10])\n","\n","train_non_text_names = os.listdir(train_non_text_dir)\n","print(train_non_text_names[:10])\n","\n","print('total training text images:', len(os.listdir(train_text_dir)))\n","print('total training non text images:', len(os.listdir(train_non_text_dir)))"],"execution_count":11,"outputs":[{"output_type":"stream","text":["['gray scale modified 1280.jpg', 'gray scale modified 447.jpg', 'gray scale modified 250.jpg', 'gray scale modified 2263.jpg', 'gray scale modified 1149.jpg', 'gray scale modified 1921.jpg', 'gray scale modified 1203.jpg', 'gray scale modified 3039.jpg', 'gray scale modified 979.jpg', 'gray scale modified 431.jpg']\n","['gray scale modified 1280.jpg', 'gray scale modified 447.jpg', 'gray scale modified 250.jpg', 'gray scale modified 2263.jpg', 'gray scale modified 1149.jpg', 'gray scale modified 1921.jpg', 'gray scale modified 1203.jpg', 'gray scale modified 979.jpg', 'gray scale modified 431.jpg', 'gray scale modified 2323.jpg']\n","total training text images: 3154\n","total training non text images: 2688\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"I2AKwFhaiv9o","colab_type":"code","colab":{}},"source":["import tensorflow as tf"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TTpfJwZCi2RF","colab_type":"code","colab":{}},"source":["model = tf.keras.models.Sequential([\n","    # Note the input shape is the desired size of the image 224x224 with 3 bytes color\n","    # This is the first convolution\n","    tf.keras.layers.Conv2D(filters = 96, kernel_size = (3, 3), strides = (4, 4), padding = 'same', activation='relu', input_shape=(224, 224, 3)),\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The second convolution\n","    tf.keras.layers.Conv2D(filters = 256, kernel_size = (11, 11), strides = (1, 1), padding = 'same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The third convolution\n","    tf.keras.layers.Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The fourth convolution\n","    tf.keras.layers.Conv2D(filters = 384, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The fifth convolution\n","    tf.keras.layers.Conv2D(filters = 256, kernel_size = (3, 3), strides = (1, 1), padding = 'same', activation='relu'),\n","    tf.keras.layers.MaxPooling2D(pool_size = (2, 2), strides = (2, 2), padding = 'same'),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # Flatten the results to feed into a Dense Layer\n","    tf.keras.layers.Flatten(),\n","    # The first 4096 Dense layer\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.4),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The second 4096 Dense layer\n","    tf.keras.layers.Dense(4096, activation='relu'),\n","    tf.keras.layers.Dropout(0.4),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # The second 1000 Dense layer\n","    tf.keras.layers.Dense(1000, activation='relu'),\n","    tf.keras.layers.Dropout(0.4),\n","    tf.keras.layers.BatchNormalization(),\n","\n","    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZTK6xw5rrT8h","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000},"outputId":"fceab847-11e2-45f4-8ce4-1cc3c9f81efe","executionInfo":{"status":"ok","timestamp":1587716338946,"user_tz":-540,"elapsed":651,"user":{"displayName":"Wonjai Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJUXJXii0iTXALRF0ZIAgTENwYzLvrIrce_oU8Uw=s64","userId":"05081401112829537892"}}},"source":["model.summary()"],"execution_count":24,"outputs":[{"output_type":"stream","text":["Model: \"sequential_1\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","conv2d_5 (Conv2D)            (None, 56, 56, 96)        2688      \n","_________________________________________________________________\n","max_pooling2d_5 (MaxPooling2 (None, 28, 28, 96)        0         \n","_________________________________________________________________\n","batch_normalization_8 (Batch (None, 28, 28, 96)        384       \n","_________________________________________________________________\n","conv2d_6 (Conv2D)            (None, 28, 28, 256)       2973952   \n","_________________________________________________________________\n","max_pooling2d_6 (MaxPooling2 (None, 14, 14, 256)       0         \n","_________________________________________________________________\n","batch_normalization_9 (Batch (None, 14, 14, 256)       1024      \n","_________________________________________________________________\n","conv2d_7 (Conv2D)            (None, 14, 14, 384)       885120    \n","_________________________________________________________________\n","max_pooling2d_7 (MaxPooling2 (None, 7, 7, 384)         0         \n","_________________________________________________________________\n","batch_normalization_10 (Batc (None, 7, 7, 384)         1536      \n","_________________________________________________________________\n","conv2d_8 (Conv2D)            (None, 7, 7, 384)         1327488   \n","_________________________________________________________________\n","max_pooling2d_8 (MaxPooling2 (None, 4, 4, 384)         0         \n","_________________________________________________________________\n","batch_normalization_11 (Batc (None, 4, 4, 384)         1536      \n","_________________________________________________________________\n","conv2d_9 (Conv2D)            (None, 4, 4, 256)         884992    \n","_________________________________________________________________\n","max_pooling2d_9 (MaxPooling2 (None, 2, 2, 256)         0         \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 2, 2, 256)         1024      \n","_________________________________________________________________\n","flatten_1 (Flatten)          (None, 1024)              0         \n","_________________________________________________________________\n","dense_4 (Dense)              (None, 4096)              4198400   \n","_________________________________________________________________\n","dropout_3 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 4096)              16384     \n","_________________________________________________________________\n","dense_5 (Dense)              (None, 4096)              16781312  \n","_________________________________________________________________\n","dropout_4 (Dropout)          (None, 4096)              0         \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 4096)              16384     \n","_________________________________________________________________\n","dense_6 (Dense)              (None, 1000)              4097000   \n","_________________________________________________________________\n","dropout_5 (Dropout)          (None, 1000)              0         \n","_________________________________________________________________\n","batch_normalization_15 (Batc (None, 1000)              4000      \n","_________________________________________________________________\n","dense_7 (Dense)              (None, 1)                 1001      \n","=================================================================\n","Total params: 31,194,225\n","Trainable params: 31,173,089\n","Non-trainable params: 21,136\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"DjfnTOYfrX1b","colab_type":"code","colab":{}},"source":["from tensorflow.keras.optimizers import RMSprop"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"R-W2S5i_rY3U","colab_type":"code","colab":{}},"source":["model.compile(loss='binary_crossentropy',\n","              optimizer=RMSprop(lr=0.001),\n","              metrics=['accuracy'])"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"negQRe8ImZgs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"803a6693-328f-47ab-d410-737c307dfb8a","executionInfo":{"status":"ok","timestamp":1587711546357,"user_tz":-540,"elapsed":614,"user":{"displayName":"Wonjai Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJUXJXii0iTXALRF0ZIAgTENwYzLvrIrce_oU8Uw=s64","userId":"05081401112829537892"}}},"source":["from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","\n","train_datagen = ImageDataGenerator(rescale=1/255)\n","\n","train_generator = train_datagen.flow_from_directory(\n","        '/tmp/text region detectoin data set/',  # This is the source directory for training images\n","        target_size=(224, 224),  # All images will be resized to 150x150\n","        batch_size=128,\n","        class_mode='binary')"],"execution_count":22,"outputs":[{"output_type":"stream","text":["Found 5840 images belonging to 2 classes.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3JBiHnufmbON","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":557},"outputId":"973aae4f-0966-4f9a-caf8-86a80311d019","executionInfo":{"status":"ok","timestamp":1587715988137,"user_tz":-540,"elapsed":4437859,"user":{"displayName":"Wonjai Lee","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhJUXJXii0iTXALRF0ZIAgTENwYzLvrIrce_oU8Uw=s64","userId":"05081401112829537892"}}},"source":["history = model.fit(\n","      train_generator,\n","      steps_per_epoch=8,  \n","      epochs=15)"],"execution_count":23,"outputs":[{"output_type":"stream","text":["Epoch 1/15\n","8/8 [==============================] - 266s 33s/step - loss: 0.4769 - accuracy: 0.8096\n","Epoch 2/15\n","8/8 [==============================] - 261s 33s/step - loss: 0.4106 - accuracy: 0.8418\n","Epoch 3/15\n","8/8 [==============================] - 267s 33s/step - loss: 0.3952 - accuracy: 0.8477\n","Epoch 4/15\n","8/8 [==============================] - 261s 33s/step - loss: 0.4771 - accuracy: 0.8125\n","Epoch 5/15\n","8/8 [==============================] - 263s 33s/step - loss: 0.3904 - accuracy: 0.8418\n","Epoch 6/15\n","8/8 [==============================] - 244s 31s/step - loss: 0.3525 - accuracy: 0.8473\n","Epoch 7/15\n","8/8 [==============================] - 263s 33s/step - loss: 0.3631 - accuracy: 0.8623\n","Epoch 8/15\n","8/8 [==============================] - 259s 32s/step - loss: 0.3507 - accuracy: 0.8604\n","Epoch 9/15\n","8/8 [==============================] - 263s 33s/step - loss: 0.3543 - accuracy: 0.8438\n","Epoch 10/15\n","8/8 [==============================] - 258s 32s/step - loss: 0.2866 - accuracy: 0.8750\n","Epoch 11/15\n","8/8 [==============================] - 261s 33s/step - loss: 0.3337 - accuracy: 0.8770\n","Epoch 12/15\n","8/8 [==============================] - 243s 30s/step - loss: 0.3148 - accuracy: 0.8781\n","Epoch 13/15\n","8/8 [==============================] - 260s 32s/step - loss: 0.3399 - accuracy: 0.8701\n","Epoch 14/15\n","8/8 [==============================] - 254s 32s/step - loss: 0.2531 - accuracy: 0.9023\n","Epoch 15/15\n","8/8 [==============================] - 255s 32s/step - loss: 0.3666 - accuracy: 0.8535\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"uVMfpmZnfUqi","colab_type":"text"},"source":[""]}]}